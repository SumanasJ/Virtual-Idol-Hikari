"""
LangGraph ä»£ç†å®ç°
æ•´åˆçŸ¥è¯†å›¾è°±ã€å‘é‡å­˜å‚¨ã€æ€§æ ¼ç³»ç»Ÿå’Œ LLM ç”Ÿæˆ
"""

from typing import TypedDict, Dict, Any, List, Optional
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from config.settings import settings
from config.prompts import IDOL_PERSONA, get_system_prompt
from core.llm.llm_manager import get_llm_manager
from core.memory.vector_store import get_vector_store
from core.memory.graph_manager import get_kg_manager
from core.personality.personality_model import create_personality_model
from core.personality.trait_evolver import create_personality_evolver
from core.agent.intent_recognizer import get_intent_recognizer


class AgentState(TypedDict):
    """ä»£ç†çŠ¶æ€"""
    # è¾“å…¥
    message: str
    session_id: str

    # ä¸­é—´çŠ¶æ€
    chat_history: List[Dict[str, str]]
    retrieved_memory: List[Dict[str, Any]]
    kg_context: Dict[str, Any]
    personality_state: Dict[str, float]

    # è¾“å‡º
    response: str

    # å…ƒæ•°æ®
    timestamp: str
    analysis: Dict[str, Any]


class VirtualIdolAgent:
    """è™šæ‹Ÿå¶åƒä»£ç†"""

    def __init__(self, session_id: Optional[str] = None):
        """
        åˆå§‹åŒ–ä»£ç†

        Args:
            session_id: ä¼šè¯ ID
        """
        self.session_id = session_id or settings.SESSION_ID
        self.llm_manager = get_llm_manager()
        self.vector_store = get_vector_store()
        self.kg_manager = get_kg_manager()
        self.personality_model = create_personality_model()
        self.personality_evolver = create_personality_evolver()

        # æ„å»ºå›¾
        self.graph = self._build_graph()
        self.chat_history: List[Dict[str, str]] = []

        print(f"âœ… è™šæ‹Ÿå¶åƒä»£ç†åˆå§‹åŒ–æˆåŠŸ (ä¼šè¯: {self.session_id})")

    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph"""
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("retrieve_memory", self._retrieve_memory_node)
        workflow.add_node("query_knowledge_graph", self._query_kg_node)
        workflow.add_node("evolve_personality", self._evolve_personality_node)
        workflow.add_node("generate_response", self._generate_response_node)
        workflow.add_node("update_knowledge", self._update_kg_node)

        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("retrieve_memory")

        # æ·»åŠ è¾¹
        workflow.add_edge("retrieve_memory", "query_knowledge_graph")
        workflow.add_edge("query_knowledge_graph", "evolve_personality")
        workflow.add_edge("evolve_personality", "generate_response")
        workflow.add_edge("generate_response", "update_knowledge")
        workflow.add_edge("update_knowledge", END)

        # ç¼–è¯‘å›¾
        return workflow.compile()

    def _retrieve_memory_node(self, state: AgentState) -> AgentState:
        """æ£€ç´¢å†å²è®°å¿†ï¼ˆå‘é‡æœç´¢ï¼‰"""
        print(f"\nğŸ” èŠ‚ç‚¹ 1: æ£€ç´¢å†å²è®°å¿†")

        query = state["message"]

        try:
            # ä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³å†å²
            results = self.vector_store.search(
                query=query,
                session_id=self.session_id,
                k=settings.K_RETRIEVAL
            )

            # è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
            retrieved = []
            for doc in results:
                retrieved.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata
                })

            state["retrieved_memory"] = retrieved
            print(f"  âœ… æ£€ç´¢åˆ° {len(retrieved)} æ¡ç›¸å…³è®°å¿†")

        except Exception as e:
            print(f"  âš ï¸  è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
            state["retrieved_memory"] = []

        return state

    def _query_kg_node(self, state: AgentState) -> AgentState:
        """æŸ¥è¯¢çŸ¥è¯†å›¾è°±"""
        print(f"\nğŸ•¸ï¸  èŠ‚ç‚¹ 2: æŸ¥è¯¢çŸ¥è¯†å›¾è°±")

        query = state["message"]

        try:
            # ä»çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç›¸å…³å­å›¾
            results = self.kg_manager.query_relevant_subgraph(
                query_text=query,
                session_id=self.session_id,
                limit=10
            )

            # è·å–ç”¨æˆ·åå¥½
            preferences = self.kg_manager.get_user_preferences(
                session_id=self.session_id,
                limit=5
            )

            state["kg_context"] = {
                "subgraph": results[:5],  # é™åˆ¶æ•°é‡
                "preferences": preferences
            }

            print(f"  âœ… æŸ¥è¯¢åˆ° {len(results)} ä¸ªå›¾èŠ‚ç‚¹, {len(preferences)} ä¸ªåå¥½")

        except Exception as e:
            print(f"  âš ï¸  çŸ¥è¯†å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
            state["kg_context"] = {"subgraph": [], "preferences": []}

        return state

    def _evolve_personality_node(self, state: AgentState) -> AgentState:
        """è¿›åŒ–æ€§æ ¼"""
        print(f"\nğŸ­ èŠ‚ç‚¹ 3: è¿›åŒ–æ€§æ ¼")

        user_input = state["message"]

        try:
            # åˆ†æç”¨æˆ·è¾“å…¥å¯¹æ€§æ ¼çš„å½±å“
            new_state = self.personality_evolver.evolve(user_input)
            state["personality_state"] = new_state.to_dict()

            print(f"  âœ… æ€§æ ¼å·²æ›´æ–°")
            print(f"     ä¸»å¯¼ç‰¹è´¨: {new_state.get_dominant_traits()[0][0]}")

        except Exception as e:
            print(f"  âš ï¸  æ€§æ ¼è¿›åŒ–å¤±è´¥: {e}")
            state["personality_state"] = self.personality_model.get_current_state().to_dict()

        return state

    def _generate_response_node(self, state: AgentState) -> AgentState:
        """ç”Ÿæˆå“åº”"""
        print(f"\nğŸ’¬ èŠ‚ç‚¹ 4: ç”Ÿæˆå“åº”")

        # æ„å›¾è¯†åˆ«
        intent_recognizer = get_intent_recognizer()
        intent = intent_recognizer.recognize(state["message"])
        intent_guidance = intent_recognizer.generate_response_guidance(intent)

        print(f"  ğŸ¯ æ„å›¾è¯†åˆ«: {intent['intent_type']}")
        if intent.get("should_be_proactive"):
            print(f"  âœ¨ åº”ä¸»åŠ¨å¯¹è¯ï¼")

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        personality_dict = state["personality_state"]

        # æ„å»ºä¸Šä¸‹æ–‡
        retrieved_context = self._format_retrieved_memory(state["retrieved_memory"])
        user_preferences = self._format_preferences(state["kg_context"]["preferences"])
        recent_topics = self._extract_topics(state["retrieved_memory"])

        system_prompt = get_system_prompt(
            name=IDOL_PERSONA["name"],
            age=IDOL_PERSONA["age"],
            personality=personality_dict,
            background=IDOL_PERSONA["background"],
            speaking_style=IDOL_PERSONA["speaking_style"],
            retrieved_context=retrieved_context,
            user_preferences=user_preferences,
            recent_topics=recent_topics
        )

        # æ·»åŠ æ„å›¾æŒ‡å¯¼åˆ° prompt
        enhanced_prompt = f"{state['message']}\n\n{intent_guidance}"

        try:
            # ä½¿ç”¨å†å²å¯¹è¯ç”Ÿæˆå“åº”
            response = self.llm_manager.generate_with_history(
                prompt=enhanced_prompt,
                chat_history=self.chat_history,
                system_prompt=system_prompt
            )

            state["response"] = response
            print(f"  âœ… å“åº”ç”ŸæˆæˆåŠŸ")

        except Exception as e:
            print(f"  âš ï¸  å“åº”ç”Ÿæˆå¤±è´¥: {e}")
            state["response"] = f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å›°æƒ‘... èƒ½å†è¯´ä¸€éå—ï¼Ÿ"

        return state

    def _update_kg_node(self, state: AgentState) -> AgentState:
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""
        print(f"\nğŸ“Š èŠ‚ç‚¹ 5: æ›´æ–°çŸ¥è¯†å›¾è°±")

        # æ„å»ºå¯¹è¯æ–‡æœ¬
        dialogue = f"ç”¨æˆ·: {state['message']}\nå¶åƒ: {state['response']}"

        try:
            # æŠ½å–å®ä½“å’Œå…³ç³»å¹¶å­˜å‚¨
            stats = self.kg_manager.extract_and_store(
                dialogue=dialogue,
                session_id=self.session_id
            )

            state["analysis"] = {
                "kg_updated": True,
                "stats": stats
            }

            print(f"  âœ… çŸ¥è¯†å›¾è°±å·²æ›´æ–°")

        except Exception as e:
            print(f"  âš ï¸  çŸ¥è¯†å›¾è°±æ›´æ–°å¤±è´¥: {e}")
            state["analysis"] = {"kg_updated": False, "error": str(e)}

        return state

    def _format_retrieved_memory(self, retrieved: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„è®°å¿†"""
        if not retrieved:
            return "æš‚æ— ç›¸å…³å†å²"

        formatted = []
        for i, item in enumerate(retrieved[:3], 1):
            formatted.append(f"{i}. {item['content'][:100]}...")

        return "\n".join(formatted)

    def _format_preferences(self, preferences: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·åå¥½"""
        if not preferences:
            return "æš‚æ— åå¥½è®°å½•"

        formatted = []
        for pref in preferences[:5]:
            pref_text = f"- {pref.get('preference', 'Unknown')}"
            if pref.get("description"):
                pref_text += f": {pref['description']}"
            formatted.append(pref_text)

        return "\n".join(formatted)

    def _extract_topics(self, retrieved: List[Dict[str, Any]]) -> str:
        """æå–æœ€è¿‘è®¨è®ºçš„è¯é¢˜"""
        if not retrieved:
            return "æš‚æ— æœ€è¿‘è¯é¢˜"

        # ç®€åŒ–çš„è¯é¢˜æå–
        topics = set()
        for item in retrieved[:5]:
            content = item.get("content", "")
            # ä»å…ƒæ•°æ®ä¸­æå–è¯é¢˜æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
            if "topic" in item.get("metadata", {}):
                topics.add(item["metadata"]["topic"])

        return ", ".join(list(topics)[:3]) if topics else "æ—¥å¸¸å¯¹è¯"

    def chat(self, message: str) -> str:
        """
        åŒæ­¥å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            ä»£ç†å“åº”
        """
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: AgentState = {
            "message": message,
            "session_id": self.session_id,
            "chat_history": self.chat_history.copy(),
            "retrieved_memory": [],
            "kg_context": {},
            "personality_state": self.personality_model.get_current_state().to_dict(),
            "response": "",
            "timestamp": datetime.now().isoformat(),
            "analysis": {}
        }

        # æ‰§è¡Œå›¾
        print(f"\n{'='*60}")
        print(f"ğŸ¤ ç”¨æˆ·: {message}")
        print(f"{'='*60}")

        final_state = self.graph.invoke(initial_state)

        # æ›´æ–°å¯¹è¯å†å²
        self.chat_history.append({"role": "user", "content": message})
        self.chat_history.append({"role": "assistant", "content": final_state["response"]})

        # ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        try:
            self.vector_store.add_conversation(
                session_id=self.session_id,
                user_message=message,
                assistant_message=final_state["response"]
            )
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")

        print(f"\n{'='*60}")
        print(f"âœ¨ å¶åƒ: {final_state['response']}")
        print(f"{'='*60}\n")

        return final_state["response"]

    def stream_chat(self, message: str):
        """
        æµå¼å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Yields:
            å“åº”æ–‡æœ¬ç‰‡æ®µ
        """
        # å…ˆæ‰§è¡Œå®Œæ•´çš„å›¾æµç¨‹ï¼ˆæµå¼åªåœ¨ç”Ÿæˆé˜¶æ®µï¼‰
        initial_state: AgentState = {
            "message": message,
            "session_id": self.session_id,
            "chat_history": self.chat_history.copy(),
            "retrieved_memory": [],
            "kg_context": {},
            "personality_state": self.personality_model.get_current_state().to_dict(),
            "response": "",
            "timestamp": datetime.now().isoformat(),
            "analysis": {}
        }

        # æ‰§è¡Œæ£€ç´¢å’Œæ€§æ ¼æ›´æ–°ï¼ˆéæµå¼éƒ¨åˆ†ï¼‰
        state = initial_state
        state = self._retrieve_memory_node(state)
        state = self._query_kg_node(state)
        state = self._evolve_personality_node(state)

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        personality_dict = state["personality_state"]
        system_prompt = get_system_prompt(
            name=IDOL_PERSONA["name"],
            age=IDOL_PERSONA["age"],
            personality=personality_dict,
            background=IDOL_PERSONA["background"],
            speaking_style=IDOL_PERSONA["speaking_style"],
            retrieved_context=self._format_retrieved_memory(state["retrieved_memory"]),
            user_preferences=self._format_preferences(state["kg_context"]["preferences"]),
            recent_topics=self._extract_topics(state["retrieved_memory"])
        )

        # æµå¼ç”Ÿæˆå“åº”
        full_response = ""
        for chunk in self.llm_manager.stream_with_history(
            prompt=message,
            chat_history=self.chat_history,
            system_prompt=system_prompt
        ):
            full_response += chunk
            yield chunk

        # æ›´æ–°çŸ¥è¯†å›¾è°±ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
        state["response"] = full_response
        self._update_kg_node(state)

        # æ›´æ–°å†å²
        self.chat_history.append({"role": "user", "content": message})
        self.chat_history.append({"role": "assistant", "content": full_response})

        # ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        try:
            self.vector_store.add_conversation(
                session_id=self.session_id,
                user_message=message,
                assistant_message=full_response
            )
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")

    def get_personality(self) -> Dict[str, float]:
        """è·å–å½“å‰æ€§æ ¼çŠ¶æ€"""
        return self.personality_model.get_current_state().to_dict()

    def get_kg_data(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†å›¾è°±æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        return self.kg_manager.get_graph_data(session_id=self.session_id)

    def reset_conversation(self) -> None:
        """é‡ç½®å¯¹è¯"""
        self.chat_history = []
        print(f"âœ… å¯¹è¯å·²é‡ç½®")


# å…¨å±€ä»£ç†å®ä¾‹ç¼“å­˜
_agents: Dict[str, VirtualIdolAgent] = {}


def get_agent(session_id: Optional[str] = None) -> VirtualIdolAgent:
    """è·å–æˆ–åˆ›å»ºä»£ç†å®ä¾‹"""
    session_id = session_id or settings.SESSION_ID

    if session_id not in _agents:
        _agents[session_id] = VirtualIdolAgent(session_id)

    return _agents[session_id]


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç†
    print("=== è™šæ‹Ÿå¶åƒä»£ç†æµ‹è¯• ===\n")

    try:
        # åˆ›å»ºä»£ç†
        agent = VirtualIdolAgent(session_id="test_session")

        # æµ‹è¯•å¯¹è¯
        print("\næµ‹è¯•å¯¹è¯æµç¨‹...\n")

        # å¯¹è¯ 1
        response1 = agent.chat("ä½ å¥½ï¼æˆ‘æ˜¯æ–°æ¥çš„ç²‰ä¸~")
        print(f"å“åº” 1: {response1}\n")

        # å¯¹è¯ 2
        response2 = agent.chat("æˆ‘å–œæ¬¢å¬é‡é‡‘å±éŸ³ä¹")
        print(f"å“åº” 2: {response2}\n")

        # å¯¹è¯ 3
        response3 = agent.chat("ä½ è¿˜è®°å¾—æˆ‘å–œæ¬¢ä»€ä¹ˆéŸ³ä¹å—ï¼Ÿ")
        print(f"å“åº” 3: {response3}\n")

        # è·å–æ€§æ ¼çŠ¶æ€
        print("å½“å‰æ€§æ ¼çŠ¶æ€:")
        personality = agent.get_personality()
        print(f"  å¼€æœ—åº¦: {personality['cheerfulness']:.2f}")
        print(f"  æ¸©æŸ”åº¦: {personality['gentleness']:.2f}")
        print(f"  å…ƒæ°”å€¼: {personality['energy']:.2f}")

        # è·å–çŸ¥è¯†å›¾è°±æ•°æ®
        print("\nçŸ¥è¯†å›¾è°±æ•°æ®:")
        kg_data = agent.get_kg_data()
        print(f"  èŠ‚ç‚¹æ•°: {len(kg_data['nodes'])}")
        print(f"  è¾¹æ•°: {len(kg_data['edges'])}")

        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
